{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from seq2seq import Seq2seq\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import run_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:uid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11be56f90>, '_model_dir': 'experiments_glove', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_tf_random_seed': None, '_save_summary_steps': 100, '_environment': 'local', '_num_worker_replicas': 0, '_task_id': 0, '_log_step_count_steps': 100, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_evaluation_master': '', '_master': ''}\n",
      "WARNING:tensorflow:uid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.\n",
      "WARNING:tensorflow:From /Users/zalexander/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:267: __init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from experiments_glove/model.ckpt-1000\n",
      "INFO:tensorflow:Saving checkpoints for 1001 into experiments_glove/model.ckpt.\n",
      "INFO:tensorflow:\n",
      "****source == a very clean and well decorated empty bathroom           \n",
      "****predict == a kitchen with an and white toilet            \n",
      "INFO:tensorflow:Starting evaluation at 2018-01-24-17:13:30\n",
      "INFO:tensorflow:Restoring parameters from experiments_glove/model.ckpt-1001\n",
      "INFO:tensorflow:Evaluation [1/10]\n",
      "INFO:tensorflow:Evaluation [2/10]\n",
      "INFO:tensorflow:Evaluation [3/10]\n",
      "INFO:tensorflow:Evaluation [4/10]\n",
      "INFO:tensorflow:Evaluation [5/10]\n",
      "INFO:tensorflow:Evaluation [6/10]\n",
      "INFO:tensorflow:Evaluation [7/10]\n",
      "INFO:tensorflow:Evaluation [8/10]\n",
      "INFO:tensorflow:Evaluation [9/10]\n",
      "INFO:tensorflow:Evaluation [10/10]\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-24-17:13:36\n",
      "INFO:tensorflow:Saving dict for global step 1001: global_step = 1001, loss = 11.6905, sim_loss = 3.51859, source_loss = 4.05188, target_loss = 4.11999\n",
      "INFO:tensorflow:Validation (step 1001): source_loss = 4.05188, loss = 11.6905, target_loss = 4.11999, sim_loss = 3.51859, global_step = 1001\n",
      "INFO:tensorflow:loss = 11.5312, step = 1001\n",
      "INFO:tensorflow:global_step/sec: 0.889435\n",
      "INFO:tensorflow:\n",
      "****source == there is a sparse kitchen with no table or chairs                  \n",
      "****predict == an image of people in a kitchen with an open                \n",
      "INFO:tensorflow:loss = 12.2477, step = 1101 (98.912 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.964301\n",
      "INFO:tensorflow:\n",
      "****source == a large kitchen and dining room in a log cabin              \n",
      "****predict == a kitchen with white cabinets and white cabinets and a             \n",
      "INFO:tensorflow:loss = 10.9953, step = 1201 (103.702 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.04448\n",
      "INFO:tensorflow:\n",
      "****source == there's plenty of red tomatoes on the kitchen counter      \n",
      "****predict == the kitchen has the counter of the wall       \n",
      "INFO:tensorflow:loss = 9.93693, step = 1301 (95.741 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02945\n",
      "INFO:tensorflow:\n",
      "****source == two dogs are sitting in a cart attached to a parked bicycle        \n",
      "****predict == two people are on a table in front of a kitchen        \n",
      "INFO:tensorflow:loss = 10.1293, step = 1401 (97.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02356\n",
      "INFO:tensorflow:\n",
      "****source == there is a person in the kitchen making a pie          \n",
      "****predict == there is a man in the middle of a bathroom          \n",
      "INFO:tensorflow:loss = 9.64992, step = 1501 (97.697 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1594 into experiments_glove/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.997022\n",
      "INFO:tensorflow:\n",
      "****source == there are many people outside having some fun       \n",
      "****predict == an old fashioned kitchen are on the kitchen       \n",
      "INFO:tensorflow:Starting evaluation at 2018-01-24-17:23:37\n",
      "INFO:tensorflow:Restoring parameters from experiments_glove/model.ckpt-1594\n",
      "INFO:tensorflow:Evaluation [1/10]\n",
      "INFO:tensorflow:Evaluation [2/10]\n",
      "INFO:tensorflow:Evaluation [3/10]\n",
      "INFO:tensorflow:Evaluation [4/10]\n",
      "INFO:tensorflow:Evaluation [5/10]\n",
      "INFO:tensorflow:Evaluation [6/10]\n",
      "INFO:tensorflow:Evaluation [7/10]\n",
      "INFO:tensorflow:Evaluation [8/10]\n",
      "INFO:tensorflow:Evaluation [9/10]\n",
      "INFO:tensorflow:Evaluation [10/10]\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-24-17:23:43\n",
      "INFO:tensorflow:Saving dict for global step 1594: global_step = 1594, loss = 10.522, sim_loss = 3.08685, source_loss = 3.75706, target_loss = 3.67812\n",
      "INFO:tensorflow:Validation (step 1601): source_loss = 3.75706, loss = 10.522, target_loss = 3.67812, sim_loss = 3.08685, global_step = 1594\n",
      "INFO:tensorflow:loss = 10.8721, step = 1601 (109.006 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.946418\n",
      "INFO:tensorflow:\n",
      "****source == a kitchen with many pots and pans hanging above the oven     \n",
      "****predict == a kitchen with white cabinets and white toilet in the kitchen    \n",
      "INFO:tensorflow:loss = 8.37512, step = 1701 (96.955 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.02531\n",
      "INFO:tensorflow:\n",
      "****source == dishes are being watched in a sudsy kitchen sink         \n",
      "****predict == two men standing in a kitchen with a table         \n",
      "INFO:tensorflow:loss = 9.06081, step = 1801 (97.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.03271\n",
      "INFO:tensorflow:\n",
      "****source == the back door of a house at night         \n",
      "****predict == the view of a large airplane is sitting         \n",
      "INFO:tensorflow:loss = 12.9193, step = 1901 (96.833 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into experiments_glove/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 10.3582.\n",
      "INFO:tensorflow:Starting evaluation at 2018-01-24-17:30:15\n",
      "INFO:tensorflow:Restoring parameters from experiments_glove/model.ckpt-2000\n",
      "INFO:tensorflow:Evaluation [1/10]\n",
      "INFO:tensorflow:Evaluation [2/10]\n",
      "INFO:tensorflow:Evaluation [3/10]\n",
      "INFO:tensorflow:Evaluation [4/10]\n",
      "INFO:tensorflow:Evaluation [5/10]\n",
      "INFO:tensorflow:Evaluation [6/10]\n",
      "INFO:tensorflow:Evaluation [7/10]\n",
      "INFO:tensorflow:Evaluation [8/10]\n",
      "INFO:tensorflow:Evaluation [9/10]\n",
      "INFO:tensorflow:Evaluation [10/10]\n",
      "INFO:tensorflow:Finished evaluation at 2018-01-24-17:30:21\n",
      "INFO:tensorflow:Saving dict for global step 2000: global_step = 2000, loss = 10.1442, sim_loss = 3.6697, source_loss = 3.23951, target_loss = 3.23501\n"
     ]
    }
   ],
   "source": [
    "run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "from seq2seq import Seq2seq\n",
    "from data_handler import Data\n",
    "\n",
    "FLAGS = tf.flags.FLAGS\n",
    "\n",
    "# Model related\n",
    "tf.flags.DEFINE_integer('num_units'         , 256           , 'Number of units in a LSTM cell')\n",
    "tf.flags.DEFINE_integer('embed_dim'         , 100           , 'Size of the embedding vector')\n",
    "\n",
    "# Training related\n",
    "tf.flags.DEFINE_float('learning_rate'       , 0.001         , 'learning rate for the optimizer')\n",
    "tf.flags.DEFINE_string('optimizer'          , 'Adam'        , 'Name of the train source file')\n",
    "tf.flags.DEFINE_integer('batch_size'        , 32            , 'random seed for training sampling')\n",
    "tf.flags.DEFINE_integer('print_every'       , 100           , 'print records every n iteration')\n",
    "tf.flags.DEFINE_integer('iterations'        , 1000         , 'number of iterations to train')\n",
    "tf.flags.DEFINE_string('model_dir'          , 'checkpoints_new' , 'Directory where to save the model')\n",
    "tf.flags.DEFINE_string('experiment_dir'          , 'experiments_glove' , 'Directory where to save the experiment')\n",
    "\n",
    "tf.flags.DEFINE_integer('input_max_length'  , 30            , 'Max length of input sequence to use')\n",
    "tf.flags.DEFINE_integer('output_max_length' , 30            , 'Max length of output sequence to use')\n",
    "tf.flags.DEFINE_integer('max_length' , 30            , 'Max length of output sequence to use')\n",
    "\n",
    "tf.flags.DEFINE_bool('use_residual_lstm'    , True          , 'To use the residual connection with the residual LSTM')\n",
    "\n",
    "# Data related\n",
    "tf.flags.DEFINE_string('input_filename', 'data/mscoco/train_source.txt', 'Name of the train source file')\n",
    "tf.flags.DEFINE_string('output_filename', 'data/mscoco/train_target.txt', 'Name of the train target file')\n",
    "tf.flags.DEFINE_string('vocab_filename', 'data/mscoco/train_vocab.txt', 'Name of the vocab file')\n",
    "tf.flags.DEFINE_string('shuffled_filename', 'data/mscoco/train_target_shuffled.txt', 'Name of shuffled targets')\n",
    "tf.flags.DEFINE_string('word_vectors', '../data/glove/glove.6B.100d.txt', 'Name of word vectors file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(FLAGS)\n",
    "data.initialize_word_vectors()\n",
    "input_fn, feed_fn = data.make_input_fn()\n",
    "features, _ = input_fn()\n",
    "feed = feed_fn()\n",
    "\n",
    "model = Seq2seq(data.vocab_size, FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec, source, target, label = model.make_graph(\n",
    "        tf.estimator.ModeKeys.TRAIN, features, None, FLAGS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = sess.run(tf.reshape(spec.rnn_output, [-1, 22946]), feed_dict={source: feed['source:0'],\n",
    "                                  target: feed['target:0'],\n",
    "                                  label: feed['label:0']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(608, 22946)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_out = sess.run(tf.cast(source, dtype=tf.int32), feed_dict={source: feed['source:0'],\n",
    "                                  target: feed['target:0'],\n",
    "                                  label: feed['label:0']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19359,  7825, 19450, 22224, 14156, 14984,  2327, 21692,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1],\n",
       "       [19359, 21692,   718, 19359,  8345, 10744,   917, 22224,  4184,\n",
       "         9458,  1656,  7361,  9413,  7133,  8775,     1,     1,     1,\n",
       "            1],\n",
       "       [19359,  4184, 22224, 21969, 21692,   718, 17692, 20310, 17065,\n",
       "        14465,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1],\n",
       "       [ 6335, 21313, 22784, 10744, 19359, 18142, 14984, 21692,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1],\n",
       "       [19359, 10868, 22784, 10744, 19359,  1625, 22224, 16487, 10744,\n",
       "        17988, 22253,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1],\n",
       "       [19359, 21974, 17008, 22784, 10744,  7361,  1625, 18667, 19253,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1],\n",
       "       [19359, 10868, 13155, 10744, 19359,  1625, 22224, 10570,  2824,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1],\n",
       "       [21989,   616, 10744, 19359, 18981, 22224, 21969,  1625,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1],\n",
       "       [19359,   909,  7558,  8714, 11826, 20513,  7361, 10057,  5287,\n",
       "        19359, 12895, 13301,     1,     1,     1,     1,     1,     1,\n",
       "            1],\n",
       "       [19359, 12895,  8714, 11826,   718, 19359, 17370,  6487, 18865,\n",
       "        15756,  7361, 18664,  8714,     1,     1,     1,     1,     1,\n",
       "            1],\n",
       "       [19359, 20352,  8714, 11826, 22224, 19359, 12895, 11916,  1656,\n",
       "         7361, 20651,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1],\n",
       "       [19359,  8714, 11826, 19111,   288, 10284, 20352,  8773,  2305,\n",
       "         8780, 19706, 10744, 19359,  8364, 13301,     1,     1,     1,\n",
       "            1],\n",
       "       [ 7361, 15052,  5924, 19754,  6166,  3083,  7361, 12943,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1],\n",
       "       [15052,  5392,  6340, 19359, 21969,  7070, 12943,   718, 17747,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1],\n",
       "       [15052,  5924, 18323,  4681, 15698,  1656, 19359, 12943,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1],\n",
       "       [19359,  1018,  6340,  7361, 12943,  6166,   718, 16994,  4681,\n",
       "        15698,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1],\n",
       "       [19359, 21100, 22224, 19359, 22171, 11767, 19359,   771, 21692,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1],\n",
       "       [19450, 19789, 21692,   718, 14471, 17499, 22224, 10661,  4962,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1],\n",
       "       [21969, 12132, 21100, 22224, 22171,  8249,  8780, 19359, 15751,\n",
       "        19433, 21692,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1],\n",
       "       [19359, 21692,   718, 22171, 22224, 21100, 22224,  4184, 17065,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1],\n",
       "       [ 6335,  2327,  1625,   718, 21969, 22224,  9115, 22253,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1],\n",
       "       [  771,  1625,  8780, 19359,  2863,  2695,   718, 15722,  7137,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1],\n",
       "       [19359, 20878, 22224, 17027, 19754,  8780, 19359,   771,  1625,\n",
       "        19253,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1],\n",
       "       [19359,   771,  1625,   718, 21100, 17027, 22224, 20878,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1],\n",
       "       [19359, 21969, 11915,  1625,   718,  8277, 17499, 19111,  3562,\n",
       "        15218,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1],\n",
       "       [19359,  1625,   718, 19359,  8277, 17499,   288,  2098,   718,\n",
       "        10390, 11620, 19359,  2228, 19359, 21100, 22224, 19359, 20878,\n",
       "            1],\n",
       "       [19359, 21969,  1625,  8780, 19359,  2695,   718,  7361, 16933,\n",
       "         1656,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1],\n",
       "       [19359, 21969,  1625,  4777, 11620,  1656,  7361,  2098,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1],\n",
       "       [ 7361, 20253, 13644, 15052,  7137,   718, 19359,  4796,  5930,\n",
       "         3424,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1],\n",
       "       [ 7361, 21692, 12602,  8773, 12517,   718, 10275, 22224,  4191,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1],\n",
       "       [19359, 19450,  3341,   718, 10275, 22224,  9883,  4283,  5357,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1],\n",
       "       [ 4834,  8773, 19359, 19450, 21692, 12602, 22224, 21100,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1]], dtype=int32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Cast:0' shape=(?, ?) dtype=int32>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.cast(source, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.get_default_graph().get_operations()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>source</td>\n",
       "      <td>Placeholder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>target</td>\n",
       "      <td>Placeholder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>label</td>\n",
       "      <td>Placeholder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>strided_slice/stack</td>\n",
       "      <td>Const</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>strided_slice/stack_1</td>\n",
       "      <td>Const</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>strided_slice/stack_2</td>\n",
       "      <td>Const</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>strided_slice</td>\n",
       "      <td>StridedSlice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>source_1</td>\n",
       "      <td>Identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shape</td>\n",
       "      <td>Shape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>strided_slice_1/stack</td>\n",
       "      <td>Const</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>strided_slice_1/stack_1</td>\n",
       "      <td>Const</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>strided_slice_1/stack_2</td>\n",
       "      <td>Const</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>strided_slice_1</td>\n",
       "      <td>StridedSlice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>zeros/shape</td>\n",
       "      <td>Pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>zeros/Const</td>\n",
       "      <td>Const</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>zeros</td>\n",
       "      <td>Fill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>encode/embed/embeddings/Initializer/random_uni...</td>\n",
       "      <td>Const</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>encode/embed/embeddings/Initializer/random_uni...</td>\n",
       "      <td>Const</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>encode/embed/embeddings/Initializer/random_uni...</td>\n",
       "      <td>Const</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>encode/embed/embeddings/Initializer/random_uni...</td>\n",
       "      <td>RandomUniform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>encode/embed/embeddings/Initializer/random_uni...</td>\n",
       "      <td>Sub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>encode/embed/embeddings/Initializer/random_uni...</td>\n",
       "      <td>Mul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>encode/embed/embeddings/Initializer/random_uni...</td>\n",
       "      <td>Add</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>encode/embed/embeddings</td>\n",
       "      <td>VariableV2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>encode/embed/embeddings/Assign</td>\n",
       "      <td>Assign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>encode/embed/embeddings/read</td>\n",
       "      <td>Identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>encode/embed/embedding_lookup</td>\n",
       "      <td>Gather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>encode/Rank</td>\n",
       "      <td>Const</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>encode/range/start</td>\n",
       "      <td>Const</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>encode/range/delta</td>\n",
       "      <td>Const</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3088</th>\n",
       "      <td>OptimizeLoss/train/update_encode/embed/embeddi...</td>\n",
       "      <td>Mul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089</th>\n",
       "      <td>OptimizeLoss/train/update_encode/embed/embeddi...</td>\n",
       "      <td>Const</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3090</th>\n",
       "      <td>OptimizeLoss/train/update_encode/embed/embeddi...</td>\n",
       "      <td>Sub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3091</th>\n",
       "      <td>OptimizeLoss/train/update_encode/embed/embeddi...</td>\n",
       "      <td>Mul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092</th>\n",
       "      <td>OptimizeLoss/train/update_encode/embed/embeddi...</td>\n",
       "      <td>Mul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3093</th>\n",
       "      <td>OptimizeLoss/train/update_encode/embed/embeddi...</td>\n",
       "      <td>Assign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3094</th>\n",
       "      <td>OptimizeLoss/train/update_encode/embed/embeddi...</td>\n",
       "      <td>ScatterAdd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3095</th>\n",
       "      <td>OptimizeLoss/train/update_encode/embed/embeddi...</td>\n",
       "      <td>Sqrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096</th>\n",
       "      <td>OptimizeLoss/train/update_encode/embed/embeddi...</td>\n",
       "      <td>Mul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3097</th>\n",
       "      <td>OptimizeLoss/train/update_encode/embed/embeddi...</td>\n",
       "      <td>Add</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3098</th>\n",
       "      <td>OptimizeLoss/train/update_encode/embed/embeddi...</td>\n",
       "      <td>RealDiv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3099</th>\n",
       "      <td>OptimizeLoss/train/update_encode/embed/embeddi...</td>\n",
       "      <td>AssignSub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3100</th>\n",
       "      <td>OptimizeLoss/train/update_encode/embed/embeddi...</td>\n",
       "      <td>NoOp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3101</th>\n",
       "      <td>OptimizeLoss/train/update_encode/rnn/lstm_cell...</td>\n",
       "      <td>ApplyAdam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3102</th>\n",
       "      <td>OptimizeLoss/train/update_encode/rnn/lstm_cell...</td>\n",
       "      <td>ApplyAdam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3103</th>\n",
       "      <td>OptimizeLoss/train/update_decode/decoder/outpu...</td>\n",
       "      <td>ApplyAdam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3104</th>\n",
       "      <td>OptimizeLoss/train/update_decode/decoder/outpu...</td>\n",
       "      <td>ApplyAdam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3105</th>\n",
       "      <td>OptimizeLoss/train/update_decode/decoder/outpu...</td>\n",
       "      <td>ApplyAdam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3106</th>\n",
       "      <td>OptimizeLoss/train/update_decode/decoder/outpu...</td>\n",
       "      <td>ApplyAdam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3107</th>\n",
       "      <td>OptimizeLoss/train/mul</td>\n",
       "      <td>Mul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3108</th>\n",
       "      <td>OptimizeLoss/train/Assign</td>\n",
       "      <td>Assign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3109</th>\n",
       "      <td>OptimizeLoss/train/mul_1</td>\n",
       "      <td>Mul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3110</th>\n",
       "      <td>OptimizeLoss/train/Assign_1</td>\n",
       "      <td>Assign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3111</th>\n",
       "      <td>OptimizeLoss/train</td>\n",
       "      <td>NoOp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3112</th>\n",
       "      <td>OptimizeLoss/control_dependency</td>\n",
       "      <td>Identity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3113</th>\n",
       "      <td>strided_slice_4/stack</td>\n",
       "      <td>Const</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3114</th>\n",
       "      <td>strided_slice_4/stack_1</td>\n",
       "      <td>Const</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3115</th>\n",
       "      <td>strided_slice_4/stack_2</td>\n",
       "      <td>Const</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3116</th>\n",
       "      <td>strided_slice_4</td>\n",
       "      <td>StridedSlice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3117</th>\n",
       "      <td>predict</td>\n",
       "      <td>Identity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3118 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   name           type\n",
       "0                                                source    Placeholder\n",
       "1                                                target    Placeholder\n",
       "2                                                 label    Placeholder\n",
       "3                                   strided_slice/stack          Const\n",
       "4                                 strided_slice/stack_1          Const\n",
       "5                                 strided_slice/stack_2          Const\n",
       "6                                         strided_slice   StridedSlice\n",
       "7                                              source_1       Identity\n",
       "8                                                 Shape          Shape\n",
       "9                                 strided_slice_1/stack          Const\n",
       "10                              strided_slice_1/stack_1          Const\n",
       "11                              strided_slice_1/stack_2          Const\n",
       "12                                      strided_slice_1   StridedSlice\n",
       "13                                          zeros/shape           Pack\n",
       "14                                          zeros/Const          Const\n",
       "15                                                zeros           Fill\n",
       "16    encode/embed/embeddings/Initializer/random_uni...          Const\n",
       "17    encode/embed/embeddings/Initializer/random_uni...          Const\n",
       "18    encode/embed/embeddings/Initializer/random_uni...          Const\n",
       "19    encode/embed/embeddings/Initializer/random_uni...  RandomUniform\n",
       "20    encode/embed/embeddings/Initializer/random_uni...            Sub\n",
       "21    encode/embed/embeddings/Initializer/random_uni...            Mul\n",
       "22    encode/embed/embeddings/Initializer/random_uni...            Add\n",
       "23                              encode/embed/embeddings     VariableV2\n",
       "24                       encode/embed/embeddings/Assign         Assign\n",
       "25                         encode/embed/embeddings/read       Identity\n",
       "26                        encode/embed/embedding_lookup         Gather\n",
       "27                                          encode/Rank          Const\n",
       "28                                   encode/range/start          Const\n",
       "29                                   encode/range/delta          Const\n",
       "...                                                 ...            ...\n",
       "3088  OptimizeLoss/train/update_encode/embed/embeddi...            Mul\n",
       "3089  OptimizeLoss/train/update_encode/embed/embeddi...          Const\n",
       "3090  OptimizeLoss/train/update_encode/embed/embeddi...            Sub\n",
       "3091  OptimizeLoss/train/update_encode/embed/embeddi...            Mul\n",
       "3092  OptimizeLoss/train/update_encode/embed/embeddi...            Mul\n",
       "3093  OptimizeLoss/train/update_encode/embed/embeddi...         Assign\n",
       "3094  OptimizeLoss/train/update_encode/embed/embeddi...     ScatterAdd\n",
       "3095  OptimizeLoss/train/update_encode/embed/embeddi...           Sqrt\n",
       "3096  OptimizeLoss/train/update_encode/embed/embeddi...            Mul\n",
       "3097  OptimizeLoss/train/update_encode/embed/embeddi...            Add\n",
       "3098  OptimizeLoss/train/update_encode/embed/embeddi...        RealDiv\n",
       "3099  OptimizeLoss/train/update_encode/embed/embeddi...      AssignSub\n",
       "3100  OptimizeLoss/train/update_encode/embed/embeddi...           NoOp\n",
       "3101  OptimizeLoss/train/update_encode/rnn/lstm_cell...      ApplyAdam\n",
       "3102  OptimizeLoss/train/update_encode/rnn/lstm_cell...      ApplyAdam\n",
       "3103  OptimizeLoss/train/update_decode/decoder/outpu...      ApplyAdam\n",
       "3104  OptimizeLoss/train/update_decode/decoder/outpu...      ApplyAdam\n",
       "3105  OptimizeLoss/train/update_decode/decoder/outpu...      ApplyAdam\n",
       "3106  OptimizeLoss/train/update_decode/decoder/outpu...      ApplyAdam\n",
       "3107                             OptimizeLoss/train/mul            Mul\n",
       "3108                          OptimizeLoss/train/Assign         Assign\n",
       "3109                           OptimizeLoss/train/mul_1            Mul\n",
       "3110                        OptimizeLoss/train/Assign_1         Assign\n",
       "3111                                 OptimizeLoss/train           NoOp\n",
       "3112                    OptimizeLoss/control_dependency       Identity\n",
       "3113                              strided_slice_4/stack          Const\n",
       "3114                            strided_slice_4/stack_1          Const\n",
       "3115                            strided_slice_4/stack_2          Const\n",
       "3116                                    strided_slice_4   StridedSlice\n",
       "3117                                            predict       Identity\n",
       "\n",
       "[3118 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pd.DataFrame([{'name': x.name, 'type': x.type} for x in tf.get_default_graph().get_operations()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decode/decoder/output_projection_wrapper/lstm_cell/kernel\n",
      "decode/decoder/output_projection_wrapper/lstm_cell/bias\n",
      "decode/decoder/output_projection_wrapper/kernel\n",
      "decode/decoder/output_projection_wrapper/bias\n",
      "OptimizeLoss/decode/decoder/output_projection_wrapper/lstm_cell/kernel/Adam\n",
      "OptimizeLoss/decode/decoder/output_projection_wrapper/lstm_cell/kernel/Adam_1\n",
      "OptimizeLoss/decode/decoder/output_projection_wrapper/lstm_cell/bias/Adam\n",
      "OptimizeLoss/decode/decoder/output_projection_wrapper/lstm_cell/bias/Adam_1\n",
      "OptimizeLoss/decode/decoder/output_projection_wrapper/kernel/Adam\n",
      "OptimizeLoss/decode/decoder/output_projection_wrapper/kernel/Adam_1\n",
      "OptimizeLoss/decode/decoder/output_projection_wrapper/bias/Adam\n",
      "OptimizeLoss/decode/decoder/output_projection_wrapper/bias/Adam_1\n"
     ]
    }
   ],
   "source": [
    "for n in d.loc[d.name.str.contains('decode') & d.type.str.contains('Variable')].name:\n",
    "    print n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('decode/decoder/output_projection_wrapper', reuse=True) as scope:\n",
    "    kernel = tf.get_variable('kernel')\n",
    "    bias = tf.get_variable('bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'decode/decoder/output_projection_wrapper/kernel:0' shape=(256, 22946) dtype=float32_ref>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'decode/decoder/output_projection_wrapper/bias:0' shape=(22946,) dtype=float32_ref>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Placeholder'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = sess.run(train_output_source.rnn_output, feed_dict={source: feed['source:0'],\n",
    "                                  target: feed['target:0'],\n",
    "                                  label: feed['label:0']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(FLAGS)\n",
    "data.initialize_word_vectors()\n",
    "\n",
    "model = Seq2seq(data.vocab_size, FLAGS, data.embeddings_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a very clean and well decorated empty bathroom\r\n",
      "a bathroom with a border of butterflies and blue paint on the walls above it\r\n",
      "a blue and white bathroom with butterfly themed wall tiles\r\n",
      "an angled view of a beautifully decorated bathroom\r\n",
      "a panoramic view of a kitchen and all of its appliances\r\n",
      "a wide angle view of the kitchen work area\r\n",
      "a panoramic photo of a kitchen and dining room\r\n",
      "multiple photos of a brown and white kitchen\r\n",
      "a graffiti ed stop sign across the street from a red car\r\n",
      "a red stop sign with a bush bumper sticker under the word stop\r\n"
     ]
    }
   ],
   "source": [
    "!head data/mscoco/train_source.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a black metal bicycle with a clock inside the front wheel\r\n",
      "a bicycle replica with a clock as the front wheel\r\n",
      "a bicycle figurine in which the front wheel is replaced with a clock\r\n",
      "the bike has a clock as a tire\r\n",
      "a black honda motorcycle with a dark burgundy seat\r\n",
      "a black honda motorcycle parked in front of a garage\r\n",
      "ma motorcycle parked on the gravel in front of a garage\r\n",
      "a honda motorcycle parked in a grass driveway\r\n",
      "this is a blue and white bathroom with a wall sink and a lifesaver on the wall\r\n",
      "a room with blue walls and a white sink and door\r\n"
     ]
    }
   ],
   "source": [
    "!head data/mscoco/test_target.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a metal clock tower on a sidewalk in front of a very tall building\r\n",
      "a group of boats on top of wet sand\r\n",
      "a kitchen with wood floors and  green counter tops\r\n",
      "a slice of pizza sitting on top of a paper plate\r\n",
      "a man with safety equipment next to a fallen tree and red fire hydrant\r\n",
      "three people are riding on an elephant's back through the jungle\r\n",
      "a teddy bear resting on a pillow in a child's bedroom\r\n",
      "a couple of people that are on their cell phone\r\n",
      "a man wearing a purple shirt  black vest and tie posing for the camera\r\n",
      "a person skating in very much snow with warm clothes\r\n"
     ]
    }
   ],
   "source": [
    "!head data/mscoco/test_target_shuffled.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = 'data/mscoco/test_target_shuffled.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1, file2, file3 = 'data/mscoco/test_target_shuffled.txt', 'data/mscoco/test_target_shuffled.txt', 'data/mscoco/test_target_shuffled.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1, file2, file3 = (re.sub('test', 'train', f) for f in (file1, file2, file3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/mscoco/train_target_shuffled.txt'"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/mscoco/train_target_shuffled.txt'"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/mscoco/train_target_shuffled.txt'"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/mscoco/test_target_shuffled.txt'"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('train', 'test', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_source.txt            train_target.txt\r\n",
      "test_target.txt            train_target_shuffled.txt\r\n",
      "test_target_shuffled.txt   train_vocab.txt\r\n",
      "train_source.txt\r\n"
     ]
    }
   ],
   "source": [
    "ls data/mscoco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source = open('data/mscoco/train_source.txt').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12811]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i, sentence in enumerate(train_source) if sentence == 'young people and their groceries in a kitchen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a cooking range is sitting in the middle of the kitchen',\n",
       " 'a group of pretty ladies and one man standing around a table',\n",
       " 'several people standing around a table with bags on it',\n",
       " 'woman and man around kitchen island with grocery bags and beverages',\n",
       " 'young people and their groceries in a kitchen',\n",
       " 'two dogs are sitting in a cart attached to a parked bicycle']"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_source[12807:12813]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = open('data/mscoco/train_target.txt').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a stove is away from the wall in a kitchen area',\n",
       " 'several people standing around a table with bags on it',\n",
       " 'a group of pretty ladies and one man standing around a table',\n",
       " 'young people and their groceries in a kitchen',\n",
       " 'woman and man around kitchen island with grocery bags and beverages',\n",
       " 'a bicycle leaning against a wall with a seat attachment behind it and two dogs sitting in the attachment']"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target[12807:12813]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_source = open('data/mscoco/test_source.txt').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target = open('data/mscoco/test_target.txt').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162024"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(test_target)\n",
    "with open('data/mscoco/test_target_shuffled.txt', 'w') as f:\n",
    "    for line in test_target:\n",
    "        f.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a bicycle replica with a clock as the front wheel\n",
      "a black metal bicycle with a clock inside the front wheel\n",
      "\n",
      "\n",
      "a black metal bicycle with a clock inside the front wheel\n",
      "a bicycle replica with a clock as the front wheel\n",
      "\n",
      "\n",
      "the bike has a clock as a tire\n",
      "a bicycle figurine in which the front wheel is replaced with a clock\n",
      "\n",
      "\n",
      "a bicycle figurine in which the front wheel is replaced with a clock\n",
      "the bike has a clock as a tire\n",
      "\n",
      "\n",
      "a black honda motorcycle parked in front of a garage\n",
      "a black honda motorcycle with a dark burgundy seat\n",
      "\n",
      "\n",
      "a black honda motorcycle with a dark burgundy seat\n",
      "a black honda motorcycle parked in front of a garage\n",
      "\n",
      "\n",
      "a honda motorcycle parked in a grass driveway\n",
      "ma motorcycle parked on the gravel in front of a garage\n",
      "\n",
      "\n",
      "ma motorcycle parked on the gravel in front of a garage\n",
      "a honda motorcycle parked in a grass driveway\n",
      "\n",
      "\n",
      "a room with blue walls and a white sink and door\n",
      "this is a blue and white bathroom with a wall sink and a lifesaver on the wall\n",
      "\n",
      "\n",
      "this is a blue and white bathroom with a wall sink and a lifesaver on the wall\n",
      "a room with blue walls and a white sink and door\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print test_source[i]\n",
    "    print test_target[i]\n",
    "    print '\\n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_handler import Data\n",
    "\n",
    "data = Data(FLAGS)\n",
    "input_fn, feed_fn = data.make_input_fn()\n",
    "features, _ = input_fn()\n",
    "feed = feed_fn()\n",
    "\n",
    "model = Seq2seq(data.vocab_size, FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output_source, loss, source, target, label = model.make_graph(\n",
    "        tf.estimator.ModeKeys.TRAIN, features, None, FLAGS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = sess.run(train_output_source.rnn_output, feed_dict={source: feed['source:0'],\n",
    "                                  target: feed['target:0'],\n",
    "                                  label: feed['label:0']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = sess.run(source, feed_dict={source: feed['source:0'],\n",
    "                                  target: feed['target:0'],\n",
    "                                  label: feed['label:0']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 16, 22946)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 16)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed = feed_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_shape = out.shape[1]\n",
    "lab_shape = actual.shape[1]\n",
    "while seq_shape == lab_shape:\n",
    "    feed = feed_fn()\n",
    "    out = sess.run(train_output_source.rnn_output, feed_dict={source: feed['source:0'],\n",
    "                                  target: feed['target:0'],\n",
    "                                  label: feed['label:0']})\n",
    "    actual = sess.run(source, feed_dict={source: feed['source:0'],\n",
    "                                  target: feed['target:0'],\n",
    "                                  label: feed['label:0']})\n",
    "    seq_shape = out.shape[1]\n",
    "    lab_shape = actual.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 30, 22946)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = tf.contrib.rnn.LSTMCell(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = tf.contrib.seq2seq.BasicDecoder(cell, helper=helper, initial_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicDecoderOutput(rnn_output=256, sample_id=TensorShape([]))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19359  7825 19450 22224 14156 14984  2327 21692     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1]\n",
      "[19359 21692   718 19359  8345 10744   917 22224  4184  9458  1656  7361\n",
      "  9413  7133  8775     1     1     1     1     1     1     1     1     1\n",
      "     1     1]\n",
      "[19359  4184 22224 21969 21692   718 17692 20310 17065 14465     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1]\n",
      "[ 6335 21313 22784 10744 19359 18142 14984 21692     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1]\n",
      "[19359 10868 22784 10744 19359  1625 22224 16487 10744 17988 22253     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1]\n",
      "[19359 21974 17008 22784 10744  7361  1625 18667 19253     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1]\n",
      "[19359 10868 13155 10744 19359  1625 22224 10570  2824     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1]\n",
      "[21989   616 10744 19359 18981 22224 21969  1625     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1]\n",
      "[19359   909  7558  8714 11826 20513  7361 10057  5287 19359 12895 13301\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1]\n",
      "[19359 12895  8714 11826   718 19359 17370  6487 18865 15756  7361 18664\n",
      "  8714     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1]\n",
      "[19359 20352  8714 11826 22224 19359 12895 11916  1656  7361 20651     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1]\n",
      "[19359  8714 11826 19111   288 10284 20352  8773  2305  8780 19706 10744\n",
      " 19359  8364 13301     1     1     1     1     1     1     1     1     1\n",
      "     1     1]\n",
      "[ 7361 15052  5924 19754  6166  3083  7361 12943     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1]\n",
      "[15052  5392  6340 19359 21969  7070 12943   718 17747     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1]\n",
      "[15052  5924 18323  4681 15698  1656 19359 12943     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1]\n",
      "[19359  1018  6340  7361 12943  6166   718 16994  4681 15698     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1]\n",
      "[19359 21100 22224 19359 22171 11767 19359   771 21692     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1]\n",
      "[19450 19789 21692   718 14471 17499 22224 10661  4962     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1]\n",
      "[21969 12132 21100 22224 22171  8249  8780 19359 15751 19433 21692     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1]\n",
      "[19359 21692   718 22171 22224 21100 22224  4184 17065     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1]\n",
      "[ 6335  2327  1625   718 21969 22224  9115 22253     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1]\n",
      "[  771  1625  8780 19359  2863  2695   718 15722  7137     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1]\n",
      "[19359 20878 22224 17027 19754  8780 19359   771  1625 19253     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1]\n",
      "[19359   771  1625   718 21100 17027 22224 20878     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1]\n",
      "[19359 21969 11915  1625   718  8277 17499 19111  3562 15218     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1]\n",
      "[19359  1625   718 19359  8277 17499   288  2098   718 10390 11620 19359\n",
      "  2228 19359 21100 22224 19359 20878     1     1     1     1     1     1\n",
      "     1     1]\n",
      "[19359 21969  1625  8780 19359  2695   718  7361 16933  1656     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1]\n",
      "[19359 21969  1625  4777 11620  1656  7361  2098     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1]\n",
      "[ 7361 20253 13644 15052  7137   718 19359  4796  5930  3424     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1]\n",
      "[ 7361 21692 12602  8773 12517   718 10275 22224  4191     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1]\n",
      "[19359 19450  3341   718 10275 22224  9883  4283  5357     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1]\n",
      "[ 4834  8773 19359 19450 21692 12602 22224 21100     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1]\n"
     ]
    }
   ],
   "source": [
    "for a in actual:\n",
    "    print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 27)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 26)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 19, 22946)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "832"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32*26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "608"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32*19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19359,  7825, 19450, 22224, 14156, 14984,  2327, 21692,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "           1,     1,     1,     1,     1,     1,     1,     1])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source\n",
      "target\n",
      "label\n"
     ]
    }
   ],
   "source": [
    "for op in  sess.graph.get_operations():\n",
    "    if re.search('laceholder', op.type):\n",
    "        print op.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicDecoderOutput(rnn_output=<tf.Tensor 'decode/decoder/transpose:0' shape=(?, ?, 22946) dtype=float32>, sample_id=<tf.Tensor 'decode/decoder/transpose_1:0' shape=(?, ?) dtype=int32>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_output_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib import layers\n",
    "\n",
    "def encode(seq, reuse=None):\n",
    "    input_lengths  = tf.reduce_sum(tf.to_int32(tf.not_equal(seq, 1)), 1)\n",
    "    input_embed    = layers.embed_sequence(seq,\n",
    "                                           vocab_size=vocab_size,\n",
    "                                           embed_dim =embed_dim,\n",
    "                                           scope = 'embed',\n",
    "                                           reuse = reuse)\n",
    "    cell = tf.contrib.rnn.LSTMCell(num_units=num_units, reuse=reuse)\n",
    "    if FLAGS.use_residual_lstm:\n",
    "        cell = tf.contrib.rnn.ResidualWrapper(cell)\n",
    "    encoder_outputs, encoder_final_state = tf.nn.dynamic_rnn(cell, input_embed, dtype=tf.float32)\n",
    "#     encoder_final_state = tf.concat(encoder_final_state, 1)\n",
    "    return encoder_final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(encoder_out, scope, output=None, mode='train', reuse=None):\n",
    "\n",
    "    # From the encoder\n",
    "    encoder_outputs = encoder_out[0]\n",
    "    encoder_state = encoder_out[1]\n",
    "    input_lengths = encoder_out[2]\n",
    "\n",
    "    # Perform the embedding\n",
    "    if mode=='train':\n",
    "        if output is None:\n",
    "            raise Exception('output must be provided for mode=train')\n",
    "        train_output   = tf.concat([tf.expand_dims(start_tokens, 1), output], 1)\n",
    "        output_lengths = tf.reduce_sum(tf.to_int32(tf.not_equal(train_output, 1)), 1)\n",
    "        output_embed   = layers.embed_sequence(\n",
    "            train_output,\n",
    "            vocab_size=vocab_size,\n",
    "            embed_dim = embed_dim,\n",
    "            scope = 'encode/embed', reuse = True)\n",
    "\n",
    "    # Prepare the helper\n",
    "    if mode=='train':\n",
    "        helper = tf.contrib.seq2seq.TrainingHelper(output_embed, output_lengths)\n",
    "    if mode=='predict':\n",
    "        helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "            embeddings,\n",
    "            start_tokens=tf.to_int32(start_tokens),\n",
    "            end_token=1\n",
    "            )\n",
    "        \n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "        cell = tf.contrib.rnn.LSTMCell(num_units=num_units)\n",
    "        out_cell = tf.contrib.rnn.OutputProjectionWrapper(cell, vocab_size, reuse=reuse)\n",
    "        decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "            cell=out_cell, helper=helper,\n",
    "            initial_state=encoder_state\n",
    "            )\n",
    "        outputs = tf.contrib.seq2seq.dynamic_decode(\n",
    "            decoder=decoder, output_time_major=False,\n",
    "            impute_finished=True, maximum_iterations=FLAGS.output_max_length)\n",
    "\n",
    "        return outputs[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_loss(self, decoding, actual):\n",
    "        train_output = tf.concat([tf.expand_dims(self.start_tokens, 1), actual], 1)\n",
    "        weights = tf.to_float(tf.not_equal(train_output[:, :-1], 1))\n",
    "        # tf.identity(decoding.rnn_output[0], name='decoder_output')\n",
    "        # tf.identity(actual[0], name='actual')\n",
    "        loss = tf.contrib.seq2seq.sequence_loss(decoding.rnn_output,\n",
    "                                                actual,\n",
    "                                                # average_across_timesteps=True,\n",
    "                                                # average_across_batch=True,\n",
    "                                                weights=weights)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = params.embed_dim\n",
    "num_units = params.num_units\n",
    "\n",
    "# Data\n",
    "source, target, label   = features['source'], features['target'], features['label']\n",
    "batch_size     = tf.shape(source)[0]\n",
    "start_tokens   = tf.zeros([batch_size], dtype= tf.int64)\n",
    "\n",
    "with tf.variable_scope('encode'):\n",
    "    source_encoder_out = encode(source)\n",
    "    target_encoder_out = encode(target, reuse=True)\n",
    "\n",
    "# Save embeddings\n",
    "with tf.variable_scope('encode/embed', reuse=True):\n",
    "    embeddings = tf.get_variable('embeddings')\n",
    "\n",
    "# From the encoder\n",
    "# encoder_state = source_encoder_out[1]\n",
    "\n",
    "train_output   = tf.concat([tf.expand_dims(start_tokens, 1), source], 1)\n",
    "output_lengths = tf.reduce_sum(tf.to_int32(tf.not_equal(train_output, 1)), 1)\n",
    "output_embed   = layers.embed_sequence(\n",
    "    train_output,\n",
    "    vocab_size=vocab_size,\n",
    "    embed_dim = embed_dim,\n",
    "    scope = 'encode/embed', reuse = True)\n",
    "\n",
    "helper = tf.contrib.seq2seq.TrainingHelper(output_embed, output_lengths)\n",
    "with tf.variable_scope('decode', reuse=None):\n",
    "    cell = tf.contrib.rnn.LSTMCell(num_units=num_units)\n",
    "    out_cell = tf.contrib.rnn.OutputProjectionWrapper(cell, vocab_size, reuse=None)\n",
    "    decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "        cell=out_cell, helper=helper,\n",
    "        initial_state=source_encoder_out\n",
    "        )\n",
    "\n",
    "train_output_source = decode(source_encoder_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = tf.contrib.seq2seq.dynamic_decode(\n",
    "    decoder=decoder, output_time_major=False,\n",
    "    impute_finished=True, maximum_iterations=FLAGS.output_max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encode/embed/embeddings\n",
      "encode/rnn/lstm_cell/kernel\n",
      "encode/rnn/lstm_cell/bias\n",
      "decoder/output_projection_wrapper/lstm_cell/kernel\n",
      "decoder/output_projection_wrapper/lstm_cell/bias\n",
      "decoder/output_projection_wrapper/kernel\n",
      "decoder/output_projection_wrapper/bias\n"
     ]
    }
   ],
   "source": [
    "for op in  sess.graph.get_operations():\n",
    "    if re.search('Variable', op.type):\n",
    "        print op.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
